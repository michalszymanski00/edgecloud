# monitoring/rules/edge-agent.rules.yml
groups:
  - name: EdgeAgent
    rules:
      # Alert if an agent hasn't sent a heartbeat recently
      - alert: HeartbeatStalled
        # Metric name from your Go code: heartbeats_sent_total
        expr: increase(heartbeats_sent_total[5m]) == 0
        # Alert fires if the condition remains true for 10 minutes
        for: 10m
        labels:
          severity: critical # Set severity level
        annotations:
          # Use labels like 'instance' (automatically added by Prometheus) for context
          summary: "Agent {{ $labels.instance }} heartbeat stalled"
          description: "Edge agent instance {{ $labels.instance }} sent no heartbeats in the last 10 minutes."

      # Alert if an agent is experiencing errors fetching workflows
      - alert: FetchErrorsHigh
        # Metric name from your Go code: workflows_fetch_errors_total
        expr: increase(workflows_fetch_errors_total[5m]) > 0
        # Alert fires if the condition remains true for 5 minutes
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Agent {{ $labels.instance }} has workflow fetch errors"
          description: "Edge agent {{ $labels.instance }} encountered workflow fetch errors in the last 5 minutes."

      # Alert (info level) if an agent has no jobs scheduled (might be normal)
      - alert: NoJobsScheduled
        # Metric name from your Go code: jobs_scheduled
        expr: jobs_scheduled == 0
        # Alert fires if the condition remains true for 5 minutes
        for: 5m
        labels:
          # Consider if 'warning' is more appropriate if 0 jobs is always an issue
          severity: info
        annotations:
          summary: "Agent {{ $labels.instance }} has no jobs scheduled"
          description: "Edge agent {{ $labels.instance }} has zero active cron jobs scheduled."

